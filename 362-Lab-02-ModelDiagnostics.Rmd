---
title: "Lab 2: Model Diagnostics"
author: 'MTH 362: Statistical Modeling'
date: "Updated `r Sys.Date()`"
output: 
  html_document: 
    toc: TRUE
    toc_float: TRUE
    theme: cosmo
    code_download: TRUE
---

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
```

```{css, echo=FALSE}
# This code chunk sets the "blockquotes" to use a blue font with a grey background
# If you prefer a different colorscheme, feel free to modify

blockquote {
  background: #e7e7e7;
  border-left: solid #0054a6;
  color: #0054a6;
}
```

The goal of this assignment is to: (1) explore what model diagnostic measures and plots should look like when a model is correctly specified, and (2) what model diagnostics and plots look like when the model is incorrectly specified.

Answer the questions below in the spaces provided (leave the ">" sign in place). When you're finished:

1. Change your name in the "author:" space at the top of this document.
2. Click the "Knit" button at the top to create an HTML file with your answers. 
3. Review your answers, make any changes as necessary, and re-"Knit".
4. Save your HTML file and upload to BlueLine. 

_You can also submit a Word or PDF copy of your work if you prefer (you'll need a LaTeX compiler to create a PDF.) If you go the Word/PDF route, please pay attention to page breaks in the compiled document, you may need to mess with the formatting options._

```{r, warning=FALSE, message=FALSE}
library(tidyverse)
```

One of the most important tools in a statistician's arsenal for understanding a statistical model is the __simulation study__.

Here's the basic idea:

1. Generate a set of data using the some pre-specified population parameters.
2. Fit a particular model to your generated data. Do you get estimated parameters that are "close" to your population parameters?

Simulation studies allow us to see when a particular model performs well. More importantly, they let us see the shortcomings of a model. That is, how far can the model assumptions be pushed before the model becomes ineffective?

## Simulating data

Let's start with a basic multiple regression problem. We'll use two explanatory variables (one categorical, one numerical) as inputs for our numerical response variable.

Our "population model" is:

$$Y = 1 + 2X_1 + 1X_2 + 2(X_1X_2)$$

We'll assume:

$$X_1 \sim Uniform(0, 1)$$

$$X_{2}=\begin{cases}
1 & P(X_2=1)=0.6\\
0 & P(X_2=0)=0.4
\end{cases}$$

$$\epsilon_i \sim Normal(0, 1)$$

The code chunk below will generate 100 observations from this model.

```{r}
n <- 100

X1 <- runif(n=n, min=0, max=1)
X2 <- rbinom(n=n, size=1, prob=0.6)

Y <- 1 + 2*X1+1*X2 + 2*X1*X2 + rnorm(n=n, mean=0, sd=1)

data <- tibble(X1=X1, X2=X2, Y=Y)

data %>% ggplot(aes(x=X1, y=Y)) + 
  geom_point(aes(col=as.factor(X2)))
```

## Question 1

The code chunk below fits a multiple regression model according to the "correct" data specification. 

```{r}
model <- lm(Y ~ X1+X2+X1*X2, data=data)
summary(model)
```

a) Write the fitted linear model.

> Write your response here.

b) Compare the actual model parameters to the "correct" parameters. How close are the estimates?

> Write your response here.

c) Use the `plot()` function to produce residual plots. Examine the first two residual plots. Based on these plots, are the LINE assumptions met?

> Write your response here.

d) Calculate the __mean squared error__ (sample code below). Based on the mean squared error formula, what values suggest a "good" model?

> Write your response here.

$$MSE = \frac{1}{n}\sum_{i=1}^n (Y_i - \hat{Y}_i)$$

```{r, eval=FALSE}
sum((data$Y - model$fitted.values)^2)/n
```

## Question 2

Now, misspecify your model. The Google slides deck linked on BlueLine includes a list of incorrect models. Choose one (be sure to write your group number next to the model you've chosen, there should be one per group).

a) Write the fitted linear model.

> Write your response here.

b) Use the `plot()` function to produce residual plots. Examine the first two residual plots. Based on these plots, are the LINE assumptions met?

> Write your response here.

c) Calculate the __mean squared error__.

> Write your response here.

d) What is your model "missing"? How is that manifested in the plots and MSE?

> Write your response here.

---

Choose one group member to serve as reporter. Add your residual plots and MSE to the Google doc, and be prepared to report back about your model.
