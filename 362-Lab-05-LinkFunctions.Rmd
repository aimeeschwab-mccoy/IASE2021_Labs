---
title: "Lab 5: The Missing Link (Function)"
subtitle: 'Your Name Here'
author: 'MTH 362: Statistical Modeling'
date: "Updated `r Sys.Date()`"
output: 
  html_document: 
    toc: TRUE
    toc_float: TRUE
    theme: cosmo
    code_download: TRUE
---

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
```

```{css, echo=FALSE}
# This code chunk sets the "blockquotes" to use a blue font with a grey background
# If you prefer a different colorscheme, feel free to modify

blockquote {
  background: #e7e7e7;
  border-left: solid #0054a6;
  color: #0054a6;
}
```


The goal of this assignment is to practice choosing the "best" link function on real data.

- Groups 1 and 2: Complete Investigation 1
- Groups 3 and 4: Complete Investigation 2

Each group should designate a "reporter" to share their findings.

```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(colorblindr)
```

It turns out that there are more options available than just the _canonical link_.

Distribution|R package|Link functions
---|-----|-----
Normal/Gaussian|`stats`|identity, log, inverse
Binomial|`stats`|logit, probit, cauchit, log, cloglog
Gamma|`stats`|inverse, identity, log
Poisson|`stats`|log, identity, sqrt
Negative binomial|`MASS`|log, sqrt, identity

How do we choose? In some situations, an _alternative link_ function might:

1. Be more interpretable in context
2. Give more accurate results

## Alternative links for binomial response

Let $p$ represent the probability of success.

1. __Probit link__: Assumes that the response variable assumes an underlying, unobservable Gaussian (normal) process that is visible to us only as a "success" or "failure". The probability $p$ corresponds to the area under the normal curve.

```{r, warning=FALSE, message=FALSE}
ggplot(NULL, aes(c(-3,3))) +
  geom_area(stat = "function", fun = dnorm, 
            fill = "#019cbd", xlim = c(-3, 1)) +
  geom_area(stat = "function", fun = dnorm, 
            fill = "grey80", xlim = c(1, 3)) + 
  labs(x='x', title='Probit link')
```

2. __Cauchit link__: Same idea as the probit link, however the underlying process is Cauchy-distributed.

```{r}
ggplot(NULL, aes(c(-3,3))) +
  geom_area(stat = "function", fun = dcauchy, 
            fill = "#ffa300", xlim = c(-3, 1)) +
  geom_area(stat = "function", fun = dcauchy, 
            fill = "grey80", xlim = c(1, 3)) + 
  labs(x='x', title='Cauchit link')
```

$$f(x;x_{0},\gamma )={\frac  {1}{\pi \gamma \left[1+\left({\frac  {x-x_{0}}{\gamma }}\right)^{2}\right]}}={1 \over \pi \gamma }\left[{\gamma ^{2} \over (x-x_{0})^{2}+\gamma ^{2}}\right]$$

The Cauchy distribution:

- Has two parameters, $x_0$ specifies the peak of the distribution and $\gamma$ specifies the variability (1/2 of the interquartile range).
- Is similar to the normal distribution, with fatter "tails".
- Is often called "pathological" by statisticians, $E(X)$ and $V(X)$ are undefined.

3. __Log link__: Take the natural log of the probability.

$$\eta = log(p)$$

4. __Complementary-log-log link__: Useful for data where most of the probabilities lie close to zero or close to 1

$$\eta = log(-log(1-p))$$

## How do the link functions compare?

1. The logit and probit are the most common link functions for the binomial, by far.
2. The probit model requires numerical integration to solve (no closed form integral for the normal distribution). Same for the cauchit model.
3. The logit, probit, and cauchit are all symmetric around $p=0.5$, whereas the cloglog link is skewed.
4. Differences between the link functions are more pronounced for large $p$ than small $p$.

```{r, warning=FALSE, message=FALSE, echo=FALSE}
p <- seq(from=0, to=1, length=1000)
invlog <- log(p/(1-p))
invprob <- qnorm(p, mean=0, sd=1)
invcauch <- qcauchy(p)
cloglog <- log(-log(1-p))
log <- log(p)

data <- tibble(p, invlog, invprob, invcauch, cloglog, log)

library(gridExtra)

p1 <- data %>% ggplot(aes(x=invprob, y=p)) + geom_line(col='grey') +  geom_line(aes(x=invcauch, y=p), col='grey') + xlim(-5, 5) + geom_line(aes(x=cloglog, y=p), col='grey') + geom_line(aes(x=log, y=p), col='grey') + geom_line(aes(x=invlog, y=p), col='#0054a6') + labs(x='Linear predictor', y='Probability', title='Logit link')

p2 <- data %>% ggplot(aes(x=log, y=p)) + geom_line(col='grey') + geom_line(aes(x=invlog, y=p), col='grey') + geom_line(aes(x=invcauch, y=p), col='grey') + xlim(-5, 5) + geom_line(aes(x=cloglog, y=p), col='grey') + geom_line(aes(x=invprob, y=p), col='#019cbd') + labs(x='Linear predictor', y='Probability', title='Probit link')

p3 <- data %>% ggplot(aes(x=invprob, y=p)) + geom_line(col='grey') + geom_line(aes(x=invlog, y=p), col='grey')  + xlim(-20, 20) + geom_line(aes(x=cloglog, y=p), col='grey') + geom_line(aes(x=log, y=p), col='grey') + geom_line(aes(x=invcauch, y=p), col='#ffa300') + labs(x='Linear predictor', y='Probability', title='Cauchit link')

p4 <- data %>% ggplot(aes(x=invprob, y=p)) + geom_line(col='grey') + geom_line(aes(x=invlog, y=p), col='grey') + geom_line(aes(x=invcauch, y=p), col='grey') + xlim(-5, 5) + geom_line(aes(x=cloglog, y=p), col='grey') + geom_line(aes(x=log, y=p), col='#800080') + labs(x='Linear predictor', y='Probability', title='Log link')

p5 <- data %>% ggplot(aes(x=invprob, y=p)) + geom_line(col='grey') + geom_line(aes(x=invlog, y=p), col='grey') + geom_line(aes(x=invcauch, y=p), col='grey') + xlim(-5, 5)  + geom_line(aes(x=log, y=p), col='grey') + geom_line(aes(x=cloglog, y=p), col='#73b865') + labs(x='Linear predictor', y='Probability', title='C-log-log link')

grid.arrange(p1, p2, p3, p4, p5, nrow=2)
```

## Investigation 1: Graduate school admission

A researcher is interested in how variables, such as GRE scores, GPA, and prestige of the undergraduate institution impact admission into graduate school. The response variable is whether or not the student was admitted into graduate school.

```{r}
admissions <- read.csv("https://stats.idre.ucla.edu/stat/data/binary.csv")
head(admissions)
```

__Question 1__: Plot each potential explanatory variable against admission. Which variables will be better predictors of graduate school admission success?

__Question 2__: Fit the following five models to predict graduate school admission based on a student's GRE, GPA, and school rank.

1) `model1: logit link`
2) `model2: probit link`
3) `model3: cauchit link`
4) `model4: log link`
5) `model5: cloglog link`

For each model, record the coefficients and significant variables ($*$) in the table below. Code to implement `model1` is provided to serve as a guide.

Model|(Intercept)|GRE|GPA|Rank
----|------------|----|----|----
Model1|-3.449548 $*$|0.002294 $*$|0.777014 $*$|-0.560031 $*$
Model2|  |  |  |
Model3|  |  |  |
Model4|  |  |  |
Model5|  |  |  |

- Using a single asterisk in an RMarkdown document *will automatically italicize any text between it and the following asterisk*. That could make your table look... interesting. To work around that, use the LaTeX asterisk $*$.

```{r}
model1 <- glm(admit ~ gre + gpa + rank, data=admissions, family=binomial(link=logit))
summary(model1)
```

__Question 3__: Compare and contrast the model coefficients. Which models are similar, and which are different?

__Question 4__: For each model, calculate and record the AIC and results of the deviance test. Which link function provides a better fit?

Model|AIC|Deviance p-value
----|------------|--------------
Model1|467.4418|0.01510054
Model2|  |  
Model3|  |  
Model4|  |  
Model5|  |  

```{r}
AIC(model1)
1 - pchisq(model1$deviance, model1$df.residual)
```

__Question 5__: Add the predicted values from each of the five models to your original data set. Calculate the correlation matrix - the correlation between all predicted values from the five models. How are the predictions from the five models related to each other?

```{r}
admissions <- admissions %>%
  mutate(model1_pred = model1$fitted.values)
cor(admissions)

# You might find the following package/function helpful for understanding correlations between variables

#install.packages('PerformanceAnalytics')
library(PerformanceAnalytics)
admissions %>% chart.Correlation()
```

__Question 6__: Which link function would you choose for this data set? Explain your answer.

## Investigation 2: Teacher training

Researchers wanted to study the effects of additional teacher training on elementary student math scores. They selected four schools, and identified six teachers within each school to participate. Each teacher has a class of twenty students.

- Four schools
- Six teachers within each school
- Twenty students per teacher

For now, we'll ignore the school-level effect. That means that we have 24 teachers (4*6) to use in our experiment. All teachers will be implementing a new math curriculum at the beginning of the school year. Suppose the teachers are randomized to four different groups:

1. Three days of professional development training
2. Two days of professional development training
3. One day of professional development training
4. No additional professional development training (control)

Is the number of professional development days a good predictor for the proportion of students passing the required math exam at the end of the year? The data set from this study is stored as `teacher_training.csv`.

```{r}
# Make sure to change this to your file directory
teacher_training <- read.csv("C:/Users/ads67836/OneDrive - Creighton University/MTH 362 - Statistical Modeling/In-Class Activities/teacher_training.csv")

head(teacher_training)
```

__Question 1__: Plot the number of professional development days (`PDT`) against the proportion of students passing the required math exam. Is there a relationship between professional development and a class's pass rate?

__Question 2__: Fit the following five models to predict pass rate based on professional development training.

1) `model1: logit link`
2) `model2: probit link`
3) `model3: cauchit link`
4) `model4: log link`
5) `model5: cloglog link`

For each model, record the coefficients and significant variables ($*$) in the table below. Code to implement `model1` is provided to serve as a guide.

Model|(Intercept)|PDT
----|------------|----|
Model1|0.4866 $*$|1.1098 $*$
Model2|  |  
Model3|  |  
Model4|  |  
Model5|  |  

```{r}
model1 <- glm(prop ~ PDT, weights=n, data=teacher_training, family=binomial(link=logit))
summary(model1)
```

__Question 3__: Compare and contrast the model coefficients. Which models are similar, and which are different?

__Question 4__: For each model, calculate and record the AIC and results of the deviance test. Which link function provides a better fit?

Model|AIC|Deviance p-value
----|------------|--------------
Model1|80.51159|0.3215861
Model2|  |  
Model3|  |  
Model4|  |  
Model5|  |  

```{r}
AIC(model1)
1 - pchisq(model1$deviance, model1$df.residual)
```

__Question 5__: Add the predicted values from each of the five models to your original data set. Calculate the correlation matrix - the correlation between all predicted values from the five models. How are the predictions from the five models related to each other?

```{r, warning=FALSE}
teacher_training <- teacher_training %>%
  mutate(model1_pred = model1$fitted.values)
cor(teacher_training)

teacher_training %>% chart.Correlation()
```

__Question 6__: Which link function would you choose for this data set? Explain your answer.